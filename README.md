### LLM Trivia API

This project is a simple Flask-based API that serves trivia questions generated by a local LLM (Large Language Model) using `ollama`. It leverages the `deepseek-r1:1.5b` model to generate multiple-choice trivia questions in JSON format.

üöÄ Requirements
    - Python 3.7+
    - `ollama` installed and set up locally
    - The `deepseek-r1:1.5b` model pulled (you can pull it with `ollama run deepseek-r1:1.5b`)

Install Python dependencies:

```
pip install flask
```
‚ñ∂Ô∏è Running the API

```
python flask_api.py
```
